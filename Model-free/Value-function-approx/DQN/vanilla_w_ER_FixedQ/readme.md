Algorithm in this folder implements these additional features on top of vanilla DQN:

- Experience replay
- Fixed Q values - parameters are copied from policy net to target net after every training iteration

Note: the atari environment for vanilla DQN has not been run to convergence due to resource constraints.